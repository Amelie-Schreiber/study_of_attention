{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84beaeb818504c7ab2e793f27fa112c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Sentence:', layout=Layout(width='auto'), placeholder='Enter sentence')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0ec2b182ac4a4483ae588bbb185c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Layer:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07a19d4c3e5442e93a10c4085cc303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=0, description='Head:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f725eb9a44f34635b412fa8a579b9a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Tokenize', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba49aa0db66b49c1adc7485a85567a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Tokens', layout=Layout(width='auto'), options=('Quant', 'um', ' information', ' thâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5317f1ac4214020b4c2a879cdeb19d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Compute Distances', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.         139.95894228 140.80757815 141.79311334]\n",
      " [139.95894228   0.          33.9144922   37.4516537 ]\n",
      " [140.80757815  33.9144922    0.          36.55526241]\n",
      " [141.79311334  37.4516537   36.55526241   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Model, GPT2TokenizerFast\n",
    "from scipy.spatial import distance\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = GPT2Model.from_pretrained('gpt2', output_hidden_states=True)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "\n",
    "# Create input widget for the sentence\n",
    "sentence_widget = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter sentence',\n",
    "    description='Sentence:',\n",
    "    layout=widgets.Layout(width='auto')\n",
    ")\n",
    "\n",
    "# Create widgets for layer and head selection\n",
    "layer_widget = widgets.IntText(value=0, description='Layer:')\n",
    "head_widget = widgets.IntText(value=0, description='Head:')\n",
    "\n",
    "# Create button to tokenize sentence\n",
    "tokenize_button = widgets.Button(description='Tokenize')\n",
    "\n",
    "# Placeholder for tokens widget\n",
    "tokens_widget = None\n",
    "\n",
    "# Placeholder for compute distances button\n",
    "compute_button = None\n",
    "\n",
    "def tokenize_sentence(b):\n",
    "    global tokens_widget, compute_button\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    sentence = sentence_widget.value\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", return_offsets_mapping=True)\n",
    "    tokens = [sentence[start:end] for start, end in inputs['offset_mapping'][0]]\n",
    "    \n",
    "    # Create checkboxes for each token\n",
    "    tokens_widget = widgets.SelectMultiple(\n",
    "        options=tokens,\n",
    "        rows=10,\n",
    "        description='Tokens',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='auto')\n",
    "    )\n",
    "    \n",
    "    # Create button to compute distances\n",
    "    compute_button = widgets.Button(description='Compute Distances')\n",
    "    compute_button.on_click(compute_distances)\n",
    "    \n",
    "    # Display widgets\n",
    "    display(tokens_widget, compute_button)\n",
    "\n",
    "def compute_distances(b):\n",
    "    # Get selected tokens\n",
    "    selected_tokens = list(tokens_widget.value)\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    sentence = sentence_widget.value\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    \n",
    "    # Forward pass through model\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "    # Extract the hidden states\n",
    "    hidden_states = outputs.hidden_states\n",
    "    \n",
    "    # Get layer and head values\n",
    "    layer = layer_widget.value\n",
    "    head = head_widget.value\n",
    "    \n",
    "    # Extract context vectors for specified layer and head\n",
    "    context_vectors = hidden_states[layer][0]\n",
    "    \n",
    "    # Select the context vectors for the selected tokens\n",
    "    selected_vectors = torch.stack([context_vectors[i] for i in range(len(context_vectors)) if tokenizer.decode(inputs['input_ids'][0][i]) in selected_tokens])\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    pairwise_distances = distance.pdist(selected_vectors.detach().numpy(), 'euclidean')\n",
    "    \n",
    "    # Convert the condensed distance matrix to a square form\n",
    "    pairwise_distances = distance.squareform(pairwise_distances)\n",
    "    \n",
    "    # Print the pairwise distance matrix\n",
    "    print(pairwise_distances)\n",
    "\n",
    "# Link button click to function\n",
    "tokenize_button.on_click(tokenize_sentence)\n",
    "\n",
    "# Display widgets\n",
    "display(sentence_widget, layer_widget, head_widget, tokenize_button)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pairwise distances between the context vectors of a collection of words reflect how the model understands the relationships between these words within a given context (sentence or paragraph). \n",
    "\n",
    "1. **If the pairwise distances do not change in different contexts:**\n",
    "\n",
    "    This could reflect a few things about the words and the model:\n",
    "    \n",
    "    * **Linguistic property:** It may suggest that the semantic relationships between the words are relatively stable across different contexts. This could be the case for words that have a fixed or limited set of meanings, or words that are strongly related to each other in some way.\n",
    "    \n",
    "    * **About the model:** It might indicate that the model is not sensitive to changes in context for these words, or that the specific layer and head selected does not encode context-sensitive information. GPT-2, like other transformers, is designed to capture context in its representations, but not all layers and heads capture this equally.\n",
    "\n",
    "2. **If the pairwise distances change significantly in different contexts:**\n",
    "\n",
    "    This could reflect a few things about the words and the model:\n",
    "    \n",
    "    * **Linguistic property:** It may suggest that the words have multiple meanings (polysemy) or that their semantic relationships are highly context-dependent. This could be the case for words that change their meaning based on the context they are used in.\n",
    "    \n",
    "    * **About the model:** It suggests that the model is sensitive to changes in context for these words, and that the specific layer and head selected are capturing this context-sensitive information. This would be expected behavior for a language model like GPT-2, which is designed to encode context in its representations.\n",
    "\n",
    "Remember that the interpretation of these distances also depends on the layer and head chosen for the analysis. Different layers and heads of the model capture different types of information, so the same words may have different distances in different layers/heads. Now, because we want to understand the concept encoded by the subset of words as a whole, we don't want to simply compare distance matrices as matrices by using something like the Frobenius norm. We lose geometric information this way. What we really want to do is compute the persistent homology associated to the point cloud using something like Gudhi, then compare the persistence barcode diagrams using something like bottleneck or Wasserstein distance. This allows us to consider topology of the concept encoded by the subset of words as a whole. If the persistence barcode diagrams are very near to each other then the concept is stable across different concepts. Note, depending on hwo often the words co-occur in data empirically, this may or may not be a good thing. It could indicate that the model is properly encoding a strong relationship among the words, but it could also indicate that model is not sensitive enough to context and therefore is not expressive enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
