{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivariance of Group Self-Attention with LoRAs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Group Equivariant Stand-Alone Self-Attention For Vision](https://openreview.net/forum?id=JkfYjnOEo6M&noteId=dxKhFZNxn-D), there are a few calculation errors in the proof of the equivariance of group self-attention layers. Below is a and explanation of why the proof of the equivariance property does not work. Let $L_g[f](i, h_1) = L_yL_{h_3}[f](i, h_1) = f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_1)$ be a $g$-transformed input signal, where $g = (y, h_3) \\in G = \\mathbb{R}^{d_{in}} \\rtimes \\mathcal{H}$. The group self-attention operation on $L_g[f]$ is given by:\n",
    "\n",
    "\\begin{align}\n",
    "m_G^r[L_yL_{h_3}[f], \\rho](i, h_1) &= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)}\\Bigg( \\langle \\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1) , \\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) \\\\\n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) \\rangle \\Bigg)\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2)) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)} \\Bigg( \\langle \\varphi_{qry}^{head}f(x^{-1}(h_3^{-1} (x(i)-y)), h_3^{-1}h_1) , \\varphi_{key}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2) \\\\ \n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) \\rangle \\Bigg) \\varphi_{val}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2)) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_h[\\rho]((x^{-1}(h_3^{-1}x(\\overline{i})+y), h_3h_1'), (x^{-1}(h_3^{-1}x(\\overline{j})+y), h_3h_2')) ) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\n",
    "\\end{align}\n",
    "\n",
    "Here, we have used $\\overline{i} = x^{-1}(h_3^{-1}(x(i)-y)) \\implies i = x^{-1}(h_3^{-1}x(\\overline{i})+y)$, and $\\overline{j} = x^{-1}(h_3^{-1}(x(j)-y)) \\implies j = x^{-1}(h_3^{-1}x(\\overline{j})+y)$, and $h_1' = h_3^{-1}h_1$ and $h_2' = h_3^{-1}h_2$. By using the definition of $L_h\\rho((i, h_1), (j, h_2)) = \\rho^P(h^{-1}(x(j) - x(i)), h^{-1}h_1^{-1}h_2)$ we can further reduce the equations:\n",
    "\n",
    "\\begin{align}\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + \\rho^P(h^{-1}(h_3x(\\overline{j})+y - (h_3x(\\overline{i})+y)), h^{-1}(h_3h_1')^{-1}(h_3h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + \\rho^P(h^{-1}(h_3x(\\overline{j}) - h_3x(\\overline{i})), h^{-1}{h'}_1^{-1}h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg) \\quad \\text{notice the lack of a factor of } h_3^{-1} \\text{ in front of } {h'}_1^{-1}h_2' \\text{ here}\\\\\n",
    "&\\neq \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_{h_3^{-1}h}[\\rho](\\overline{i}, h_1'), (\\overline{j}, h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\n",
    "\\end{align}\n",
    "\n",
    "So, we see that $m_G^r[L_yL_{h_3}[f], \\rho](i, h) \\neq L_yL_{h_3}[m_G^r[f, \\rho]](i, h)$. It is also said in [Group Equivariant Stand-Alone Self-Attention For Vision](https://openreview.net/forum?id=JkfYjnOEo6M&noteId=dxKhFZNxn-D) that the equivariance of group self-attention is due to the relative positional encoding being **invariant** to the group action. That is, it is claimed to follow from $L_g[\\rho](i, j) = \\rho(i, j)$. This however is false. In particular, the positional encoding $\\rho(i, j)$ is not used in the proof, it is the positional encoding $\\rho((i, h_1), (j, h_2))$ that is used. Furthermore, we see that it is not $G$-invariant unless $x(j)-x(i)$ is an $H$-invariant vector. \n",
    "\n",
    "\\begin{align}\n",
    "L_g[\\rho]((i, h_1), (j, h_2)) &= L_yL_h[\\rho]((i, h_1), (j, h_2))\\\\\n",
    "                              &= L_h[L_y[\\rho]]((i, h_1), (j, h_2))\\\\\n",
    "                              &= L_h[\\rho]((x^{-1}(x(i)-y), h_1), (x^{-1}(x(j)-y), h_2))\\\\\n",
    "                              &= \\rho((x^{-1}(h^{-1}(x(i)-y)), h^{-1}h_1), (x^{-1}(h^{-1}(x(j)-y)), h^{-1}h_2))\\\\\n",
    "                              &= \\rho^P(h^{-1}(x(j)-y) - h^{-1}(x(i)-y) , (h^{-1}h_1)^{-1}(h^{-1}h_2))\\\\\n",
    "                              &= \\rho^P(h^{-1}(x(j)-x(i)) , (h^{-1}h_1)^{-1}(h^{-1}h_2))\\\\\n",
    "                              &= \\rho^P(h^{-1}(x(j)-x(i)), h_1^{-1}hh^{-1}h_2)\\\\\n",
    "                              &= \\rho^P(h^{-1}(x(j)-x(i)), h_1^{-1}h_2) \\\\\n",
    "                              &\\neq \\rho((i, h_1), (j, h_2)) \\quad \\text{unless } h^{-1}(x(j)-x(i)) = x(j)-x(i)\n",
    "\\end{align}\n",
    "\n",
    "This means that group self-attention is not group equivariant, as is. The other proofs in the paper do in fact work, however. If we redefine $L_h[\\rho]((i, h_1), (j, h_2))$ as $\\rho^P(h^{-1}(x(j) - x(i)), h_1^{-1}h_2)$ we see that equivariance does in fact hold, and that the positional encoding is $\\mathcal{H}$-invariant in the group component. However, it is unclear whether or not this change is appropriate. Regardless, assuming that this change can in fact be made, we can show the following:\n",
    "\n",
    "\\begin{align}\n",
    "m_G^r[L_yL_{h_3}[f], \\rho](i, h_1) &= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)}\\Bigg( \\langle \\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1) , \\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) \\\\\n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) \\rangle \\Bigg)\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2)) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)} \\Bigg( \\langle \\varphi_{qry}^{head}f(x^{-1}(h_3^{-1} (x(i)-y)), h_3^{-1}h_1) , \\varphi_{key}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2) \\\\ \n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) \\rangle \\Bigg) \\varphi_{val}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2)) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_h[\\rho]((x^{-1}(h_3^{-1}x(\\overline{i})+y), h_3h_1'), (x^{-1}(h_3^{-1}x(\\overline{j})+y), h_3h_2')) ) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\n",
    "\\end{align}\n",
    "\n",
    "Here we are making the substitutions for $\\overline{i}$ and $\\overline{j}$ as before. Next we use the new defintion of the positional encoding and further reduce the equations: \n",
    "\n",
    "\\begin{align}\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + \\rho^P(h^{-1}(h_3x(\\overline{j})+y - (h_3x(\\overline{i})+y)), (h_3h_1')^{-1}(h_3h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + \\rho^P(h^{-1}(h_3x(\\overline{j}) - h_3x(\\overline{i})), {h'}_1^{-1}h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_{h_3^{-1}h}[\\rho](\\overline{i}, h_1'), (\\overline{j}, h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\n",
    "\\end{align}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including LoRAs Preserves Equivariance\n",
    "\n",
    "Next, we can also show that the inclusion of LoRAs does not disrupt equivariance. \n",
    "\n",
    "\\begin{align}\n",
    "m_{G, LoRA}^r[L_yL_{h_3}[f], \\rho](i, h_1) &= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)}\\Bigg( \\langle \\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1) + \\Delta\\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1), \\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) \\\\\n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) + \\Delta\\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) + L_h[\\rho]((i, h_1), (j, h_2))) \\rangle \\Bigg)\\\\\n",
    "&\\quad (\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2)) + \\Delta\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2))) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)} \\Bigg( \\langle \\varphi_{qry}^{head}f(x^{-1}(h_3^{-1} (x(i)-y)), h_3^{-1}h_1) + \\Delta\\varphi_{qry}^{head}f(x^{-1}(h_3^{-1} (x(i)-y)), h_3^{-1}h_1), \\varphi_{key}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2) \\\\ \n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) + \\Delta\\varphi_{key}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2) + L_h[\\rho]((i, h_1), (j, h_2))) \\rangle \\Bigg)\\\\ \n",
    "&\\quad (\\varphi_{val}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2)) + \\Delta\\varphi_{val}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2))) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') + \\Delta\\varphi_{qry}^{head}f(\\overline{i}, h_1'), \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_h[\\rho]((x^{-1}(h_3^{-1}x(\\overline{i})+y), h_3h_1'), (x^{-1}(h_3^{-1}x(\\overline{j})+y), h_3h_2')) ) + \\Delta\\varphi_{key}^{head}(f(\\overline{j}, h_2') + L_h[\\rho]((x^{-1}(h_3^{-1}x(\\overline{i})+y), h_3h_1'), (x^{-1}(h_3^{-1}x(\\overline{j})+y), h_3h_2'))) \\rangle \\Bigg)\\\\\n",
    "&\\quad (\\varphi_{val}^{head}(f(\\overline{j}, h_2')) + \\Delta\\varphi_{val}^{head}(f(\\overline{j}, h_2'))) \\Bigg)\n",
    "\\end{align}\n",
    "\n",
    "Next, we use the definition of $L_h[\\rho]((i, h_1), (j, h_2))$ to reduce the equations further:\n",
    "\n",
    "\\begin{align}\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') + \\Delta\\varphi_{qry}^{head}f(\\overline{i}, h_1'), \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + \\rho^P(h^{-1}(h_3x(\\overline{j})+y - (h_3x(\\overline{i})+y)), (h_3h_1')^{-1}(h_3h_2')) + \\Delta\\varphi_{key}^{head}(f(\\overline{j}, h_2') + \\rho^P(h^{-1}(h_3x(\\overline{j})+y - (h_3x(\\overline{i})+y)), (h_3h_1')^{-1}(h_3h_2'))) \\rangle \\Bigg)(\\varphi_{val}^{head}(f(\\overline{j}, h_2')) + \\Delta\\varphi_{val}^{head}(f(\\overline{j}, h_2'))) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') + \\Delta\\varphi_{qry}^{head}f(\\overline{i}, h_1'), \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + \\rho^P(h^{-1}(h_3x(\\overline{j}) - h_3x(\\overline{i})), {h'}_1^{-1}h_2') + \\Delta\\varphi_{key}^{head}(f(\\overline{j}, h_2') + \\rho^P(h^{-1}(h_3x(\\overline{j}) - h_3x(\\overline{i})), {h'}_1^{-1}h_2')) \\rangle \\Bigg)(\\varphi_{val}^{head}(f(\\overline{j}, h_2')) + \\Delta\\varphi_{val}^{head}(f(\\overline{j}, h_2'))) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') + \\Delta\\varphi_{qry}^{head}f(\\overline{i}, h_1'), \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_{h_3^{-1}h}[\\rho](\\overline{i}, h_1'), (\\overline{j}, h_2')) + \\Delta\\varphi_{key}^{head}(f(\\overline{j}, h_2') + L_{h_3^{-1}h}[\\rho](\\overline{i}, h_1'), (\\overline{j}, h_2')) \\rangle \\Bigg)(\\varphi_{val}^{head}(f(\\overline{j}, h_2')) + \\Delta\\varphi_{val}^{head}(f(\\overline{j}, h_2'))) \\Bigg)\n",
    "\\end{align}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since $G$ is assumed unimodular (or compact) we have that the following summations are equal, \n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))}[\\bullet] = \\sum_{(x^{-1}(h_3x(\\overline{j})), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})), h_3h_1'))}[\\bullet] = \\sum_{(x^{-1}(x(\\overline{j})), h_2') \\in N(x^{-1}(x(\\overline{i})), h_1')}[\\bullet] = \\sum_{(\\overline{j}, h_2') \\in N(\\overline{i}, h_1')}[\\bullet]\n",
    "\\end{equation}\n",
    "\n",
    "We also have that $\\sum_{h_3h \\in \\mathcal{H}}[\\bullet] = \\sum_{h \\in \\mathcal{H}}[\\bullet]$. Finally, we make the following observations, \n",
    "\n",
    "\\begin{align}\n",
    "&m_{G, LoRA}^r[L_yL_{h_3}[f], \\rho](i, h_1) \\\\\n",
    "&= \\varphi_{out}\\Bigg( \\bigcup_{head \\in [H]}\\sum_{h \\in \\mathcal{H}}\\sum_{(\\overline{j}, h_2') \\in N(\\overline{i}, h_1')}\\sigma_{(\\overline{j}, h_2')}\\Bigg(\\langle \\varphi_{qry}^{head}(f(\\overline{i}, h_1')) + \\Delta\\varphi_{qry}^{head}(f(\\overline{i}, h_1')) , \\varphi_{key}^{head}(f(\\overline{j}, h_2') + \\\\\n",
    "&\\quad L_{h_3^{-1}h}[\\rho]((\\overline{i}, h_1'), (\\overline{j}, h_2')) + \\Delta\\varphi_{key}^{head}(f(\\overline{j}, h_2') + L_{h_3^{-1}h}[\\rho]((\\overline{i}, h_1'), (\\overline{j}, h_2'))) \\rangle\\Bigg)(\\varphi_{val}^{head}(f(\\overline{j}, h_2')) + \\Delta\\varphi_{val}^{head}(f(\\overline{j}, h_2')))\\Bigg)\\\\\n",
    "&= m_{G, LoRA}^r[f, \\rho](\\overline{i}, h_3^{-1}h_1)\\\\\n",
    "&= m_{G, LoRA}^r[f, \\rho](x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_1)\\\\\n",
    "&= L_yL_{h_3}[m_{G, LoRA}^r[f, \\rho]](i, h_1)\n",
    "\\end{align}\n",
    "\n",
    "So, we see that in fact $m_{G, LoRA}^r[L_yL_{h_3}[f], \\rho](i, h) = L_yL_{h_3}[m_{G, LoRA}^r[f, \\rho]](i, h)$, and LoRAs do not disrupt equivariance of group self-attention. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see for the following setup, that the same arguments work if we include a LoRA $\\Delta\\varphi_{out}$ for $\\varphi_{out}$. In particular, including such a LoRA does not disrupt the equivariance of the group self-attention layers. \n",
    "\n",
    "\\begin{align}\n",
    "m_{G, LoRA}^r[L_yL_{h_3}[f], \\rho](i, h_1) &= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)}\\Bigg( \\langle \\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1) + \\Delta\\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1), \\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) \\\\\n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) + \\Delta\\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) + L_h[\\rho]((i, h_1), (j, h_2))) \\rangle \\Bigg)\\\\\n",
    "&\\quad (\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2)) + \\Delta\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2))) \\Bigg) \\\\\n",
    "& \\quad + \\Delta\\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)}\\Bigg( \\langle \\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1) + \\Delta\\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1), \\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) \\\\\n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) + \\Delta\\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) + L_h[\\rho]((i, h_1), (j, h_2))) \\rangle \\Bigg)\\\\\n",
    "&\\quad (\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2)) + \\Delta\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2))) \\Bigg)\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
