{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mending a Proof of the Equivariance of Group Self-Attention\n",
    "\n",
    "In [](), there are a few calculation errors in the proof of the equivariance of group self-attention layers. Below is a mended proof of the equivariance property. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $L_g[f](i, h_1) = L_yL_{h_3}[f](i, h_1) = f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_1)$ be a $g$-transformed input signal, where $g = (y, h_3) \\in G = \\mathbb{R}^{d_{in}} \\rtimes \\mathcal{H}$. The group self-attention operation on $L_g[f]$ is given by:\n",
    "\n",
    "\\begin{align}\n",
    "m_G^r[L_yL_{h_3}[f], \\rho](i, h_1) &= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)}\\Bigg( \\langle \\varphi_{qry}^{head}L_yL_{h_3}[f](i, h_1) , \\varphi_{key}^{head}(L_yL_{h_3}[f](j, h_2) \\\\\n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) \\rangle \\Bigg)\\varphi_{val}^{head}(L_yL_{h_3}[f](j, h_2)) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h \\in \\mathcal{H}} \\sum_{(j, h_2) \\in N(i, h_1)} \\sigma_{(j, h_2)} \\Bigg( \\langle \\varphi_{qry}^{head}f(x^{-1}(h_3^{-1} (x(i)-y)), h_3^{-1}h_1) , \\varphi_{key}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2) \\\\ \n",
    "&\\quad + L_h[\\rho]((i, h_1), (j, h_2)) ) \\rangle \\Bigg) \\varphi_{val}^{head}(f(x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h_2)) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h' \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_h[\\rho]((x^{-1}(h_3^{-1}x(\\overline{i})+y), h_3h_1'), (x^{-1}(h_3^{-1}x(\\overline{j})+y), h_3h_2')) ) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\n",
    "\\end{align}\n",
    "\n",
    "Here, we have used $\\overline{i} = x^{-1}(h_3^{-1}(x(i)-y)) \\implies i = x^{-1}(h_3^{-1}x(\\overline{i})+y)$, and $\\overline{j} = x^{-1}(h_3^{-1}(x(j)-y)) \\implies j = x^{-1}(h_3^{-1}x(\\overline{j})+y)$, and $h_1' = h_3^{-1}h_1$ and $h_2' = h_3^{-1}h_2$. By using the definition of $\\rho((i, h_1), (j, h_2))$ we can further reduce the equations:\n",
    "\n",
    "\\begin{align}\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h' \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + \\rho^P(h^{-1}(h_3x(\\overline{j})+y - (h_3x(\\overline{i})+y)), h^{-1}(h_3h_1')^{-1}(h_3h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h' \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + \\rho^P(h^{-1}(h_3x(\\overline{j} - h_3x\\overline{i})), h^{-1}{h'}_1^{-1}h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\\\\\n",
    "&= \\varphi_{out} \\Bigg( \\bigcup_{head \\in [H]} \\sum_{h_3h' \\in \\mathcal{H}} \\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N((x^{-1}(h_3x(\\overline{i})+y), h_3h_1'))} \\sigma_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2')}\\Bigg( \\langle \\varphi_{qry}^{head}f(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_{h_3^{-1}h}[\\rho](\\overline{i}, h_1'), (\\overline{j}, h_2')) \\rangle \\Bigg)\\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\n",
    "\\end{align}\n",
    "\n",
    "Now, since we are working with unimodular (or compact) groups, the area of summation remains equal for any transformation $g \\in \\mathcal{G}$, and we have:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{(x^{-1}(h_3x(\\overline{j})+y), h_3h_2') \\in N(x^{-1}(h_3x(\\overline{i})+y), h_3h_1')}[\\bullet] = \\sum_{(x^{-1}(h_3x(\\overline{j})), h_3h_2') \\in N(x^{-1}(h_3x(\\overline{i})), h_3h_1')}[\\bullet] = \\sum_{(x^{-1}(x(\\overline{j})), h_2') \\in N(x^{-1}(x(\\overline{i})), h_1')}[\\bullet] = \\sum_{(\\overline{j}, h_2') \\in N(\\overline{i}, h_1')}[\\bullet]\n",
    "\\end{equation}\n",
    "\n",
    "Additionally, we have \n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{h_3h' \\in \\mathcal{H}}[\\bullet] = \\sum_{h' \\in \\mathcal{H}}[\\bullet]\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, \n",
    "\n",
    "\\begin{align}\n",
    "m_G^r[L_yL_{h_3}[f], \\rho](i, h) &= \\varphi_{out}\\Bigg( \\bigcup_{head \\in [H]} \\sum_{h' \\in \\mathcal{H}} \\sum_{(\\overline{j}, h_2') \\in N(\\overline{i}, h_1')} \\sigma_{(\\overline{j}, h_2')} \\Bigg( \\langle \\varphi_{qry}^{head}(f(\\overline{i}, h_1')) , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad L_{h_3^{-1}h}[\\rho]((\\overline{i}, h_1'), (\\overline{j}, h_2'))) \\rangle \\Bigg) \\varphi_{val}^{head}(f(\\overline{j}, h_2')) \\Bigg)\\\\\n",
    "&= m_G^r[f, \\rho](\\overline{i}, h_3^{-1}h) \\\\\n",
    "&= m_G^r[f, \\rho](x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h)\\\\\n",
    "&= L_yL_{h_3}[m_G^r[f, \\rho]](i, h)\n",
    "\\end{align}\n",
    "\n",
    "So, we see that $m_G^r[L_yL_{h_3}[f], \\rho](i, h) = L_yL_{h_3}[m_G^r[f, \\rho]](i, h)$. This means that group self-attention is group equivariant. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in LoRAs Preserves Equivariance\n",
    "\n",
    "Now, we would also like to prove the equivariance of a model that includes LoRAs. Let's rewrite the modified self-attention mechanism by incorporating the LoRAs for the query, key, and value functions, after the reductions that are obtained in a manner analogous to the above reductions:\n",
    "\n",
    "\\begin{align}\n",
    "m_G^r[L_yL_{h_3}[f], \\rho](i, h) &= \\varphi_{out}\\Bigg( \\bigcup_{head \\in [H]} \\sum_{h' \\in \\mathcal{H}} \\sum_{(\\overline{j}, h_2') \\in N(\\overline{i}, h_1')} \\sigma_{(\\overline{j}, h_2')} \\Bigg( \\langle \\varphi_{qry}^{head}(f(\\overline{i}, h_1')) + \\Delta \\varphi_{qry}^{head}(\\overline{i}, h_1') , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_{h_3^{-1}h}[\\rho]((\\overline{i}, h_1'), (\\overline{j}, h_2')) + \\Delta \\varphi_{key}^{head}(f(\\overline{j}, h_2') + L_{h_3^{-1}h}[\\rho]((\\overline{i}, h_1'), (\\overline{j}, h_2'))) \\rangle \\Bigg) (\\varphi_{val}^{head}(f(\\overline{j}, h_2')) + \\Delta \\varphi_{val}^{head}(\\overline{j}, h_2')) \\Bigg) \\\\\n",
    "\\end{align}\n",
    "\n",
    "From this we have: \n",
    "\n",
    "\\begin{align}\n",
    "m_{G, LoRA}^r[L_yL_{h_3}[f], \\rho](i, h) &= \\varphi_{out}\\Bigg( \\bigcup_{head \\in [H]} \\sum_{h' \\in \\mathcal{H}} \\sum_{(\\overline{j}, h_2') \\in N(\\overline{i}, h_1')} \\sigma_{(\\overline{j}, h_2')} \\Bigg( \\langle \\varphi_{qry}^{head}(f(\\overline{i}, h_1')) + \\Delta\\varphi_{qry}^{head}(f(\\overline{i}, h_1')) , \\varphi_{key}^{head}(f(\\overline{j}, h_2') \\\\\n",
    "&\\quad + L_{h_3^{-1}h}[\\rho]((\\overline{i}, h_1') + \\Delta\\varphi_{key}^{head}(f(\\overline{j}, h_2') + L_{h_3^{-1}h}[\\rho]((\\overline{i}, h_1'), (\\overline{j}, h_2'))) \\rangle \\Bigg) (\\varphi_{val}^{head}(f(\\overline{j}, h_2'))\\Delta \\varphi_{val}^{head}(\\overline{j}, h_2'))) \\Bigg)\\\\\n",
    "&= m_{G, LoRA}^r[f, \\rho](\\overline{i}, h_3^{-1}h) \\\\\n",
    "&= m_{G, LoRA}^r[f, \\rho](x^{-1}(h_3^{-1}(x(i)-y)), h_3^{-1}h)\\\\\n",
    "&= L_yL_{h_3}[m_{G, LoRA}^r[f, \\rho]](i, h)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
